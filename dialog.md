# Dialogue readings


### Regulation
1. [Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations](http://arxiv.org/pdf/1605.07154.pdf)


### Policy Transfer
1. [Dialogue policy learning for combinations of noise and user simulation: transfer results](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.141.6098&rep=rep1&type=pdf)<br/>
`--Compare policy transfer properties under different environment, and show that policy trained under high-noise conditions has better transfer properties.`
2. [Personalizing a Dialogue System with Transfer Learning](https://arxiv.org/abs/1610.02891)<br/>
`--Two Q networks, Q_g for common knowledge, Q_p for personalized networks; each user has a trained model; first train on source domain, then train on part of target domain; test with the rest of target domain.`
3. 

### Task-Completion Dialogue
1. [A Copy-Augmented Sequence-to-Sequence Architecture Gives Good Performance on Task-Oriented Dialogue](https://arxiv.org/abs/1701.04024)<br/>
`--1). Seq2Seq (with Soft-attention for copying mechanism); 2). KB-Type encoding in Input; 3). For decoding, it does not say how to handle the (most) unseen kb-entities.`
2. [Generative Deep Neural Networks for Dialogue: A Short Review](https://arxiv.org/abs/1611.06216)<br/>
`--1). Three encoder-decoder architecture; 2). Evaluation`
3. 